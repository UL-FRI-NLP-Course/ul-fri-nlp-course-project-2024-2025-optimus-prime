{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddeab2f3",
   "metadata": {},
   "source": [
    "## Generate a response by incoroprating the retrieved papers with a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8b731",
   "metadata": {},
   "source": [
    "## Larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff40bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marko\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig, AutoConfig\n",
    "import torch\n",
    "import dotenv\n",
    "\n",
    "# Load a chat-capable model\n",
    "LLM_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = f\"cuda:{torch.cuda.current_device()}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=LLM_MODEL,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 8-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # loading in 4 bit\n",
    "    bnb_4bit_quant_type=\"nf4\", # quantization type\n",
    "    bnb_4bit_use_double_quant=True, # nested quantization\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(\n",
    "    pretrained_model_name_or_path=LLM_MODEL,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=LLM_MODEL,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config, # we introduce the bnb config here.\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97fc93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\marko\\AppData\\Local\\Temp\\ipykernel_20136\\3550628853.py:16: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=generate_text)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define the Hugging Face pipeline for text generation\n",
    "generate_text = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=8192,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "# Wrap the Hugging Face pipeline into LangChain's LLM\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful AI QA assistant, for answering queries about research methods.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e16615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful AI QA assistant, for answering queries about research methods.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Question: Which paper introduced the transformer architecture\n",
      "Answer: The transformer architecture was introduced in the paper \"Attention is All You Need\" by Vaswani et al., published in 2017.\n"
     ]
    }
   ],
   "source": [
    "# an example of something that works without rag\n",
    "chain = prompt | llm\n",
    "question = \"Which paper introduced the transformer architecture\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b84fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful AI QA assistant, for answering queries about research methods.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Question: \n",
      "Answer: I'd be happy to help answer any questions you have about research methods! However, your question is not specific enough for me to provide a clear answer. Could you please specify which research method or methods you are inquiring about? Some common research methods include surveys, experiments, case studies, and literature reviews. Once I have more information, I can provide a more accurate response.\n"
     ]
    }
   ],
   "source": [
    "# A newer one \n",
    "question = \"\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb5a202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful AI QA assistant, for answering queries about research methods.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Question: What is the latest training data you have been trained on?\n",
      "Answer: I don't have the ability to be trained on new data or to keep track of the most recent data used in my training. My knowledge base is static and based on the information available at the time of my creation.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the latest training data you have been trained on?\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccfea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful AI QA assistant, for answering queries about research methods.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Question: What can you tell me about the paper Instruct-ReID: A Multi-purpose Person Re-identification Task with Instructions\n",
      "Answer: \"Instruct-ReID\" is a research paper published in the IEEE Transactions on Pattern Analysis and Machine Intelligence journal. The authors propose a new multi-purpose person re-identification (ReID) task, which involves not only identifying the same person across different cameras but also understanding and following given instructions related to the person. This task is designed to evaluate the ability of models to reason about context and follow instructions, in addition to their ability to recognize people. The paper provides a detailed description of the dataset, evaluation metrics, and experimental results. If you need more specific information, please let me know.\n"
     ]
    }
   ],
   "source": [
    "question = \"What can you tell me about the paper Instruct-ReID: A Multi-purpose Person Re-identification Task with Instructions\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67284e4",
   "metadata": {},
   "source": [
    "## Get the papers based on the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcbae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marko\\miniconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\marko\\.cache\\huggingface\\hub\\models--sentence-transformers--allenai-specter. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank #1\n",
      "Title: Position: Foundation Agents as the Paradigm Shift for Decision Making\n",
      "Authors: Xiaoqian Liu, Xingzhou Lou, Jianbin Jiao, Junge Zhang\n",
      "Summary: Decision making demands intricate interplay between perception, memory, and\n",
      "reasoning to discern optimal policies. Conventional approaches to decision\n",
      "making face challenges related to low sample efficiency and poor\n",
      "generalization. In contrast, foundation models in language and vision have\n",
      "showcased rapid adaptation to diverse new tasks. Therefore, we advocate for the\n",
      "construction of foundation agents as a transformative shift in the learning\n",
      "paradigm of agents. This proposal is underpinned by the formulation of\n",
      "foundation agents with their fundamental characteristics and challenges\n",
      "motivated by the success of large language models (LLMs). Moreover, we specify\n",
      "the roadmap of foundation agents from large interactive data collection or\n",
      "generation, to self-supervised pretraining and adaptation, and knowledge and\n",
      "value alignment with LLMs. Lastly, we pinpoint critical research questions\n",
      "derived from the formulation and delineate trends for foundation agents\n",
      "supported by real-world use cases, addressing both technical and theoretical\n",
      "aspects to propel the field towards a more comprehensive and impactful future.\n",
      "Similarity: 0.8611\n",
      "URL: https://arxiv.org/abs/2405.17009v3\n",
      "--------------------------------------------------------------------------------\n",
      "Rank #2\n",
      "Title: Toward Efficient Exploration by Large Language Model Agents\n",
      "Authors: Dilip Arumugam, Thomas L. Griffiths\n",
      "Summary: A burgeoning area within reinforcement learning (RL) is the design of\n",
      "sequential decision-making agents centered around large language models (LLMs).\n",
      "While autonomous decision-making agents powered by modern LLMs could facilitate\n",
      "numerous real-world applications, such successes demand agents that are capable\n",
      "of data-efficient RL. One key obstacle to achieving data efficiency in RL is\n",
      "exploration, a challenge that we demonstrate many recent proposals for LLM\n",
      "agent designs struggle to contend with. Meanwhile, classic algorithms from the\n",
      "RL literature known to gracefully address exploration require technical\n",
      "machinery that can be challenging to operationalize in purely natural language\n",
      "settings. In this work, rather than relying on finetuning or in-context\n",
      "learning to coax LLMs into implicitly imitating a RL algorithm, we illustrate\n",
      "how LLMs can be used to explicitly implement an existing RL algorithm\n",
      "(Posterior Sampling for Reinforcement Learning) whose capacity for\n",
      "statistically-efficient exploration is already well-studied. We offer empirical\n",
      "results demonstrating how our LLM-based implementation of a known,\n",
      "data-efficient RL algorithm can be considerably more effective in natural\n",
      "language tasks that demand prudent exploration.\n",
      "Similarity: 0.8584\n",
      "URL: https://arxiv.org/abs/2504.20997v1\n",
      "--------------------------------------------------------------------------------\n",
      "Rank #3\n",
      "Title: AgentGym: Evolving Large Language Model-based Agents across Diverse Environments\n",
      "Authors: Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Dingwen Yang, Chenyang Liao, Xin Guo, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang\n",
      "Summary: Building generalist agents that can handle diverse tasks and evolve\n",
      "themselves across different environments is a long-term goal in the AI\n",
      "community. Large language models (LLMs) are considered a promising foundation\n",
      "to build such agents due to their generalized capabilities. Current approaches\n",
      "either have LLM-based agents imitate expert-provided trajectories step-by-step,\n",
      "requiring human supervision, which is hard to scale and limits environmental\n",
      "exploration; or they let agents explore and learn in isolated environments,\n",
      "resulting in specialist agents with limited generalization. In this paper, we\n",
      "take the first step towards building generally-capable LLM-based agents with\n",
      "self-evolution ability. We identify a trinity of ingredients: 1) diverse\n",
      "environments for agent exploration and learning, 2) a trajectory set to equip\n",
      "agents with basic capabilities and prior knowledge, and 3) an effective and\n",
      "scalable evolution method. We propose AgentGym, a new framework featuring a\n",
      "variety of environments and tasks for broad, real-time, uni-format, and\n",
      "concurrent agent exploration. AgentGym also includes a database with expanded\n",
      "instructions, a benchmark suite, and high-quality trajectories across\n",
      "environments. Next, we propose a novel method, AgentEvol, to investigate the\n",
      "potential of agent self-evolution beyond previously seen data across tasks and\n",
      "environments. Experimental results show that the evolved agents can achieve\n",
      "results comparable to SOTA models. We release the AgentGym suite, including the\n",
      "platform, dataset, benchmark, checkpoints, and algorithm implementations. The\n",
      "AgentGym suite is available on https://github.com/WooooDyy/AgentGym.\n",
      "Similarity: 0.8563\n",
      "URL: https://arxiv.org/abs/2406.04151v1\n",
      "--------------------------------------------------------------------------------\n",
      "Rank #4\n",
      "Title: Controlling Large Language Model Agents with Entropic Activation Steering\n",
      "Authors: Nate Rahn, Pierluca D'Oro, Marc G. Bellemare\n",
      "Summary: The rise of large language models (LLMs) has prompted increasing interest in\n",
      "their use as in-context learning agents. At the core of agentic behavior is the\n",
      "capacity for exploration, or the ability to actively gather information about\n",
      "the environment. But how do LLM agents explore, and how can we control their\n",
      "exploratory behaviors? To answer these questions, we take a\n",
      "representation-level perspective, and introduce Entropic Activation Steering\n",
      "(EAST), an activation steering method for in-context LLM agents. Firstly, we\n",
      "demonstrate that EAST can effectively manipulate an LLM agent's exploration by\n",
      "directly affecting the high-level actions parsed from the outputs of the LLM,\n",
      "in contrast to token-level temperature sampling. Secondly, we reveal how\n",
      "applying this control modulates the uncertainty exhibited in the LLM's\n",
      "thoughts, guiding the agent towards more exploratory actions. Finally, we\n",
      "demonstrate that the steering vectors obtained by EAST generalize across task\n",
      "variants. In total, these results show that LLM agents explicitly encode\n",
      "uncertainty over their actions in their representation space. Our work paves\n",
      "the way for a new understanding of the functioning of LLM agents and to\n",
      "effective control of their decision-making behaviors.\n",
      "Similarity: 0.8555\n",
      "URL: https://arxiv.org/abs/2406.00244v2\n",
      "--------------------------------------------------------------------------------\n",
      "Rank #5\n",
      "Title: Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study\n",
      "Authors: Shangding Gu\n",
      "Summary: Large Language Models (LLMs) have demonstrated remarkable capabilities for\n",
      "reinforcement learning (RL) models, such as planning and reasoning\n",
      "capabilities. However, the problems of LLMs and RL model collaboration still\n",
      "need to be solved. In this study, we employ a teacher-student learning\n",
      "framework to tackle these problems, specifically by offering feedback for LLMs\n",
      "using RL models and providing high-level information for RL models with LLMs in\n",
      "a cooperative multi-agent setting. Within this framework, the LLM acts as a\n",
      "teacher, while the RL model acts as a student. The two agents cooperatively\n",
      "assist each other through a process of recursive help, such as \"I help you help\n",
      "I help.\" The LLM agent supplies abstract information to the RL agent, enabling\n",
      "efficient exploration and policy improvement. In turn, the RL agent offers\n",
      "feedback to the LLM agent, providing valuable, real-time information that helps\n",
      "generate more useful tokens. This bi-directional feedback loop promotes\n",
      "optimization, exploration, and mutual improvement for both agents, enabling\n",
      "them to accomplish increasingly challenging tasks. Remarkably, we propose a\n",
      "practical algorithm to address the problem and conduct empirical experiments to\n",
      "evaluate the effectiveness of our method.\n",
      "Similarity: 0.8529\n",
      "URL: https://arxiv.org/abs/2401.06603v2\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer \n",
    "import arxiv \n",
    "\n",
    "# Load the sentence transformer model\n",
    "# TODO maybe some better model for embedding extraction, maybe we could fine tune?\n",
    "# TODO maybe somehow add citations\n",
    "# model_embeddings = SentenceTransformer('all-mpnet-base-v2')  # For embeddin extraction\n",
    "model_embeddings = SentenceTransformer('allenai-specter') # It can be used to map the titles & abstracts of scientific publications to a vector space such that similar papers are close.\n",
    "\n",
    "# Define your query\n",
    "user_query = \"Toward Efficient Exploration by Large Language Model Agents\"  # arxiv actually finds this one\n",
    "\n",
    "# Get the embedding for the query\n",
    "query_embedding = model_embeddings.encode([user_query])\n",
    "\n",
    "search = arxiv.Search(\n",
    "    query=user_query,\n",
    "    max_results=50,\n",
    "    sort_by=arxiv.SortCriterion.Relevance,\n",
    "    sort_order=arxiv.SortOrder.Descending\n",
    ")\n",
    "\n",
    "client = arxiv.Client()\n",
    "results = list(client.results(search))\n",
    "\n",
    "# Extract summaries and titles\n",
    "papers = []\n",
    "summaries = []\n",
    "for result in results:\n",
    "    title = result.title\n",
    "    authors = ', '.join([author.name for author in result.authors])\n",
    "    summary = result.summary\n",
    "    url = f\"https://arxiv.org/abs/{result.entry_id.split('/')[-1]}\"\n",
    "    papers.append({\n",
    "        \"title\": title,\n",
    "        \"authors\": authors,\n",
    "        \"summary\": summary,\n",
    "        \"url\": url\n",
    "    })\n",
    "    summaries.append(summary)\n",
    "\n",
    "# Encode all summaries\n",
    "summary_embeddings = model_embeddings.encode(summaries)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = cosine_similarity(query_embedding, summary_embeddings)[0]\n",
    "\n",
    "for i, paper in enumerate(papers):\n",
    "    paper[\"similarity\"] = similarities[i]\n",
    "\n",
    "\n",
    "top_papers = sorted(papers, key=lambda x: x[\"similarity\"], reverse=True)[:5] # top 5\n",
    "\n",
    "# Print top 5 similar papers\n",
    "for i, paper in enumerate(top_papers, 1):\n",
    "    print(f\"Rank #{i}\")\n",
    "    print(f\"Title: {paper['title']}\")\n",
    "    print(f\"Authors: {paper['authors']}\")\n",
    "    print(f\"Summary: {paper['summary']}\")\n",
    "    print(f\"Similarity: {paper['similarity']:.4f}\")\n",
    "    print(f\"URL: {paper['url']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979439cc",
   "metadata": {},
   "source": [
    "## Combine the retrieved papers and the generation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc93f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\marko\\AppData\\Local\\Temp\\ipykernel_20136\\3622334336.py:42: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
      "C:\\Users\\marko\\AppData\\Local\\Temp\\ipykernel_20136\\3622334336.py:46: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run({\"context\": context, \"question\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: You are a helpful AI QA assistant, for answering querries about research methods.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "```\n",
      "Title: Position: Foundation Agents as the Paradigm Shift for Decision Making\n",
      "Summary: Decision making demands intricate interplay between perception, memory, and\n",
      "reasoning to discern optimal policies. Conventional approaches to decision\n",
      "making face challenges related to low sample efficiency and poor\n",
      "generalization. In contrast, foundation models in language and vision have\n",
      "showcased rapid adaptation to diverse new tasks. Therefore, we advocate for the\n",
      "construction of foundation agents as a transformative shift in the learning\n",
      "paradigm of agents. This proposal is underpinned by the formulation of\n",
      "foundation agents with their fundamental characteristics and challenges\n",
      "motivated by the success of large language models (LLMs). Moreover, we specify\n",
      "the roadmap of foundation agents from large interactive data collection or\n",
      "generation, to self-supervised pretraining and adaptation, and knowledge and\n",
      "value alignment with LLMs. Lastly, we pinpoint critical research questions\n",
      "derived from the formulation and delineate trends for foundation agents\n",
      "supported by real-world use cases, addressing both technical and theoretical\n",
      "aspects to propel the field towards a more comprehensive and impactful future.\n",
      "\n",
      "Title: Toward Efficient Exploration by Large Language Model Agents\n",
      "Summary: A burgeoning area within reinforcement learning (RL) is the design of\n",
      "sequential decision-making agents centered around large language models (LLMs).\n",
      "While autonomous decision-making agents powered by modern LLMs could facilitate\n",
      "numerous real-world applications, such successes demand agents that are capable\n",
      "of data-efficient RL. One key obstacle to achieving data efficiency in RL is\n",
      "exploration, a challenge that we demonstrate many recent proposals for LLM\n",
      "agent designs struggle to contend with. Meanwhile, classic algorithms from the\n",
      "RL literature known to gracefully address exploration require technical\n",
      "machinery that can be challenging to operationalize in purely natural language\n",
      "settings. In this work, rather than relying on finetuning or in-context\n",
      "learning to coax LLMs into implicitly imitating a RL algorithm, we illustrate\n",
      "how LLMs can be used to explicitly implement an existing RL algorithm\n",
      "(Posterior Sampling for Reinforcement Learning) whose capacity for\n",
      "statistically-efficient exploration is already well-studied. We offer empirical\n",
      "results demonstrating how our LLM-based implementation of a known,\n",
      "data-efficient RL algorithm can be considerably more effective in natural\n",
      "language tasks that demand prudent exploration.\n",
      "\n",
      "Title: AgentGym: Evolving Large Language Model-based Agents across Diverse Environments\n",
      "Summary: Building generalist agents that can handle diverse tasks and evolve\n",
      "themselves across different environments is a long-term goal in the AI\n",
      "community. Large language models (LLMs) are considered a promising foundation\n",
      "to build such agents due to their generalized capabilities. Current approaches\n",
      "either have LLM-based agents imitate expert-provided trajectories step-by-step,\n",
      "requiring human supervision, which is hard to scale and limits environmental\n",
      "exploration; or they let agents explore and learn in isolated environments,\n",
      "resulting in specialist agents with limited generalization. In this paper, we\n",
      "take the first step towards building generally-capable LLM-based agents with\n",
      "self-evolution ability. We identify a trinity of ingredients: 1) diverse\n",
      "environments for agent exploration and learning, 2) a trajectory set to equip\n",
      "agents with basic capabilities and prior knowledge, and 3) an effective and\n",
      "scalable evolution method. We propose AgentGym, a new framework featuring a\n",
      "variety of environments and tasks for broad, real-time, uni-format, and\n",
      "concurrent agent exploration. AgentGym also includes a database with expanded\n",
      "instructions, a benchmark suite, and high-quality trajectories across\n",
      "environments. Next, we propose a novel method, AgentEvol, to investigate the\n",
      "potential of agent self-evolution beyond previously seen data across tasks and\n",
      "environments. Experimental results show that the evolved agents can achieve\n",
      "results comparable to SOTA models. We release the AgentGym suite, including the\n",
      "platform, dataset, benchmark, checkpoints, and algorithm implementations. The\n",
      "AgentGym suite is available on https://github.com/WooooDyy/AgentGym.\n",
      "\n",
      "Title: Controlling Large Language Model Agents with Entropic Activation Steering\n",
      "Summary: The rise of large language models (LLMs) has prompted increasing interest in\n",
      "their use as in-context learning agents. At the core of agentic behavior is the\n",
      "capacity for exploration, or the ability to actively gather information about\n",
      "the environment. But how do LLM agents explore, and how can we control their\n",
      "exploratory behaviors? To answer these questions, we take a\n",
      "representation-level perspective, and introduce Entropic Activation Steering\n",
      "(EAST), an activation steering method for in-context LLM agents. Firstly, we\n",
      "demonstrate that EAST can effectively manipulate an LLM agent's exploration by\n",
      "directly affecting the high-level actions parsed from the outputs of the LLM,\n",
      "in contrast to token-level temperature sampling. Secondly, we reveal how\n",
      "applying this control modulates the uncertainty exhibited in the LLM's\n",
      "thoughts, guiding the agent towards more exploratory actions. Finally, we\n",
      "demonstrate that the steering vectors obtained by EAST generalize across task\n",
      "variants. In total, these results show that LLM agents explicitly encode\n",
      "uncertainty over their actions in their representation space. Our work paves\n",
      "the way for a new understanding of the functioning of LLM agents and to\n",
      "effective control of their decision-making behaviors.\n",
      "\n",
      "Title: Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study\n",
      "Summary: Large Language Models (LLMs) have demonstrated remarkable capabilities for\n",
      "reinforcement learning (RL) models, such as planning and reasoning\n",
      "capabilities. However, the problems of LLMs and RL model collaboration still\n",
      "need to be solved. In this study, we employ a teacher-student learning\n",
      "framework to tackle these problems, specifically by offering feedback for LLMs\n",
      "using RL models and providing high-level information for RL models with LLMs in\n",
      "a cooperative multi-agent setting. Within this framework, the LLM acts as a\n",
      "teacher, while the RL model acts as a student. The two agents cooperatively\n",
      "assist each other through a process of recursive help, such as \"I help you help\n",
      "I help.\" The LLM agent supplies abstract information to the RL agent, enabling\n",
      "efficient exploration and policy improvement. In turn, the RL agent offers\n",
      "feedback to the LLM agent, providing valuable, real-time information that helps\n",
      "generate more useful tokens. This bi-directional feedback loop promotes\n",
      "optimization, exploration, and mutual improvement for both agents, enabling\n",
      "them to accomplish increasingly challenging tasks. Remarkably, we propose a\n",
      "practical algorithm to address the problem and conduct empirical experiments to\n",
      "evaluate the effectiveness of our method.\n",
      "```\n",
      "\n",
      "### Question:\n",
      "Toward Efficient Exploration by Large Language Model Agents\n",
      "\n",
      "### Answer:\n",
      "The article discusses an approach to enable large language model (LLM) agents to efficiently explore in reinforcement learning (RL) tasks. Instead of relying on fine-tuning or in-context learning to make LLMs implicitly follow RL algorithms, the authors propose using LLMs to explicitly implement a known, data-efficient RL algorithm called Posterior Sampling for Reinforcement Learning. They provide empirical results showing that their LLM-based implementation outperforms previous methods in terms of exploration efficiency.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Combine summaries into a context string\n",
    "context = \"\\n\\n\".join(\n",
    "    f\"Title: {paper['title']}\\nSummary: {paper['summary']}\" for paper in top_papers\n",
    ")\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful AI QA assistant, for answering querries about research methods.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=PROMPT_TEMPLATE.strip(),\n",
    ")\n",
    "\n",
    "# Define the Hugging Face pipeline for text generation\n",
    "generate_text = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,  # Replace with your model\n",
    "    tokenizer=tokenizer,  # Replace with your tokenizer\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=8192,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "\n",
    "# Wrap the Hugging Face pipeline into LangChain's LLM\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)\n",
    "\n",
    "# Create the LLMChain with the prompt template and the LLM\n",
    "qa_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    "\n",
    "# Ask the model a question and get the answer\n",
    "question = user_query # TODO maybe change this, to make it different than the search (or change the search)\n",
    "response = qa_chain.run({\"context\": context, \"question\": question})\n",
    "\n",
    "# Print the response\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54446b81",
   "metadata": {},
   "source": [
    "## Simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\one\\OneDrive\\grive\\faks\\masters\\y1\\2nd semester\\NLP\\ul-fri-nlp-course-project-2024-2025-optimus-prime\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sebas\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Papers and Generated Answer:\n",
      "Research Papers:\n",
      "Title: Neuromodulation Gated Transformer\n",
      "Summary: We introduce a novel architecture, the Neuromodulation Gated Transformer\n",
      "(NGT), which is a simple implementation of neuromodulation in transformers via\n",
      "a multiplicative effect. We compare it to baselines and show that it results in\n",
      "the best average performance on the SuperGLUE benchmark validation sets.\n",
      "\n",
      "Title: Interpretation of the Transformer and Improvement of the Extractor\n",
      "Summary: It has been over six years since the Transformer architecture was put\n",
      "forward. Surprisingly, the vanilla Transformer architecture is still widely\n",
      "used today. One reason is that the lack of deep understanding and comprehensive\n",
      "interpretation of the Transformer architecture makes it more challenging to\n",
      "improve the Transformer architecture. In this paper, we first interpret the\n",
      "Transformer architecture comprehensively in plain words based on our\n",
      "understanding and experiences. The interpretations are further proved and\n",
      "verified. These interpretations also cover the Extractor, a family of drop-in\n",
      "replacements for the multi-head self-attention in the Transformer architecture.\n",
      "Then, we propose an improvement on a type of the Extractor that outperforms the\n",
      "self-attention, without introducing additional trainable parameters.\n",
      "Experimental results demonstrate that the improved Extractor performs even\n",
      "better, showing a way to improve the Transformer architecture.\n",
      "\n",
      "Title: Atleus: Accelerating Transformers on the Edge Enabled by 3D Heterogeneous Manycore Architectures\n",
      "Summary: Transformer architectures have become the standard neural network model for\n",
      "various machine learning applications including natural language processing and\n",
      "computer vision. However,\n",
      "Generated Answer:\n",
      "Title: Atleus: Accelerating Transformers on the Edge Enabled by 3D Heterogeneous Manycore Architectures\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "model_id = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "rag = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Combine summaries into a context string, but make sure it's within the token limit\n",
    "context = \"\\n\\n\".join(\n",
    "    f\"Title: {paper['title']}\\nSummary: {paper['summary']}\" for paper in top_papers\n",
    ")\n",
    "\n",
    "# Encode the context and check its length\n",
    "input_ids = tokenizer.encode(context, return_tensors=\"pt\")\n",
    "max_length = 1700  # Adjust this based on your model's max token length\n",
    "\n",
    "# Truncate if necessary to fit within the max token limit\n",
    "if input_ids.shape[1] > max_length:\n",
    "    input_ids = input_ids[:, :max_length]\n",
    "\n",
    "\n",
    "# Prepare the prompt, ensuring it stays within the token limit\n",
    "prompt = f\"\"\"Here are some research papers:\n",
    "\n",
    "{context[:max_length]}  # Only include a truncated context if necessary\n",
    "\n",
    "Use the above research paper summaries to answer the following question:\n",
    "\n",
    "Question: {user_query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Generate the answer using the same prompt\n",
    "output = rag(prompt, max_new_tokens=300)\n",
    "\n",
    "# Provide the generated answer along with the papers\n",
    "print(\"Research Papers and Generated Answer:\")\n",
    "print(f\"Research Papers:\\n{context[:max_length]}\")  # Display truncated context\n",
    "print(f\"Generated Answer:\\n{output[0]['generated_text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
